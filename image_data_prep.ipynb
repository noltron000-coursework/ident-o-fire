{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”¥ Fire...or No Fire?\n",
    "\n",
    "## **Step 1:** Setup\n",
    "We need to set up the dataframe to initial state.\n",
    "Then we can manipulate it more in later steps, by cleaning it, digesting it, etc.\n",
    "\n",
    "### Import Packages\n",
    "> \"If I have seen further, it is by standing on the shoulders of Giants.\"<br />\n",
    "> &mdash; Isaac Newton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# glob crawler for reading files and folders\n",
    "import glob\n",
    "\n",
    "# regex parser for advanced string-parsing\n",
    "import re\n",
    "\n",
    "# pandas used for dataframe manipulation\n",
    "import pandas\n",
    "\n",
    "# numpy is used for odds and ends, like high-efficiency arrays\n",
    "import numpy\n",
    "\n",
    "# python imaging library; used for deconstructing images\n",
    "from PIL import Image\n",
    "\n",
    "# other imports are described as they are used\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl Datafiles\n",
    "The **glob** package is great and sets up our project for success.\n",
    "Be sure you have your directory-structure set up correctly as stated in the README&hellip;\n",
    "Otherwise, I cannot guarentee that this project will work for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all files from dirs in the data dir\n",
    "files = glob.glob('data/*/*.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset in an array\n",
    "dataset = []\n",
    "\n",
    "# loop through every file that \"glob\" found.\n",
    "for filepath in files:\n",
    "\t# regex used for Windows/MacOS compatibility\n",
    "\tfilecrawl = re.split(r'\\\\+|/+', filepath)\n",
    "\n",
    "\t# remove the \"data\" folder entry; its not needed\n",
    "\tfilecrawl = filecrawl[1:]\n",
    "\n",
    "\t# tag images from the fire-images folder as \"fire\"\n",
    "\tif filecrawl[0] == 'Fire images':\n",
    "\t\tfilecrawl.append(1)\n",
    "\telse:\n",
    "\t\tfilecrawl.append(0)\n",
    "\n",
    "\t# add filecrawl findings to dataset\n",
    "\tdataset.append(filecrawl)\n",
    "\t# ==NOTE==\n",
    "\t# Because the \"glob\" package arbitrarily crawls files, the\n",
    "\t# index of an item may not be the same each time this is run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>filename</th>\n",
       "      <th>fire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fire images</td>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fire images</td>\n",
       "      <td>10-9-15-2-400.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fire images</td>\n",
       "      <td>11_10_19-mjs_ft_hotel-fire_19183862.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fire images</td>\n",
       "      <td>132-img1.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fire images</td>\n",
       "      <td>132343342_21n.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        folder                                 filename  fire\n",
       "0  Fire images                                    1.jpg     1\n",
       "1  Fire images                        10-9-15-2-400.jpg     1\n",
       "2  Fire images  11_10_19-mjs_ft_hotel-fire_19183862.jpg     1\n",
       "3  Fire images                             132-img1.png     1\n",
       "4  Fire images                        132343342_21n.jpg     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>filename</th>\n",
       "      <th>fire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>Normal Images 5</td>\n",
       "      <td>x14862823.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>Normal Images 5</td>\n",
       "      <td>xbR1sVO.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>Normal Images 5</td>\n",
       "      <td>xR7vfcy.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>Normal Images 5</td>\n",
       "      <td>xsylvia-hotel-queen-room.jpg.pagespeed.ic.hw9T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>Normal Images 5</td>\n",
       "      <td>y5IQiH.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              folder                                           filename  fire\n",
       "646  Normal Images 5                                      x14862823.jpg     0\n",
       "647  Normal Images 5                                        xbR1sVO.png     0\n",
       "648  Normal Images 5                                        xR7vfcy.jpg     0\n",
       "649  Normal Images 5  xsylvia-hotel-queen-room.jpg.pagespeed.ic.hw9T...     0\n",
       "650  Normal Images 5                                         y5IQiH.jpg     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create our project's main dataframe\n",
    "dataframe = pandas.DataFrame(dataset, columns=['folder', 'filename', 'fire'])\n",
    "\n",
    "# display shows these tables neatly, shown below\n",
    "display(dataframe.head(), dataframe.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == FIXME ==\n",
    "# this does not seem to be working properly at the moment\n",
    "\n",
    "'''\n",
    "# check for any duplicate filenames in the dataframe\n",
    "duplicates = dataframe['filename'].duplicated()\n",
    "\n",
    "# Select rows with duplicate filenames\n",
    "duplicate_rows = dataframe[duplicates]\n",
    "display(duplicate_rows)\n",
    "\n",
    "# create a warning if duplicates exist\n",
    "assert duplicates.sum() == 0, '\\n' \\\n",
    "f'WARNING: there are {duplicates.sum()} duplicated filenames in the dataframe. proceed with caution.'\n",
    "'''\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebalancing Datapoints\n",
    "I used [this article][rebalancing] to help figure things out.\n",
    "\n",
    "[rebalancing]: https://towardsdatascience.com/having-an-imbalanced-dataset-here-is-how-you-can-solve-it-1640568947eb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create an object of the classifier, called \"rebalancinator\"\n",
    "rebalancinator = BalancedBaggingClassifier(\n",
    "\tbase_estimator=DecisionTreeClassifier(),\n",
    "\tsampling_strategy='auto',\n",
    "\treplacement=False,\n",
    "\trandom_state=0\n",
    ")\n",
    "\n",
    "'''\n",
    "Y_train = credit_df['Class']\n",
    "X_train = credit_df.drop(['Class'], axis=1, inplace=False)\n",
    "\n",
    "# train the classifier.\n",
    "rebalancinator.fit(X_train, Y_train)\n",
    "preds = rebalancinator.predict(X_train)\n",
    "'''\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train = credit_df['Class']\n",
    "# X_train = credit_df.drop(['Class'], axis=1, inplace=False)\n",
    "\n",
    "# # train the classifier.\n",
    "# rebalancinator.fit(X_train, Y_train)\n",
    "# preds = rebalancinator.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(852, 480)\n"
     ]
    }
   ],
   "source": [
    "img = Image.open(f'data/{dataframe[\"folder\"][0]}/{dataframe[\"filename\"][0]}')\n",
    "print(img.size)\n",
    "image_red = img.resize((1024, 1024))\n",
    "image = img_to_array(image_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[117., 131., 140.],\n",
       "        [137., 151., 160.],\n",
       "        [135., 149., 158.],\n",
       "        ...,\n",
       "        [147., 169., 183.],\n",
       "        [154., 176., 190.],\n",
       "        [131., 153., 167.]],\n",
       "\n",
       "       [[117., 131., 140.],\n",
       "        [137., 151., 160.],\n",
       "        [135., 149., 158.],\n",
       "        ...,\n",
       "        [147., 169., 183.],\n",
       "        [154., 176., 190.],\n",
       "        [131., 153., 167.]],\n",
       "\n",
       "       [[138., 152., 161.],\n",
       "        [158., 172., 181.],\n",
       "        [157., 171., 180.],\n",
       "        ...,\n",
       "        [169., 191., 205.],\n",
       "        [176., 198., 212.],\n",
       "        [153., 175., 189.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[110., 108., 130.],\n",
       "        [119., 117., 138.],\n",
       "        [113., 110., 129.],\n",
       "        ...,\n",
       "        [149., 116., 107.],\n",
       "        [147., 114., 105.],\n",
       "        [131.,  98.,  89.]],\n",
       "\n",
       "       [[111., 103., 118.],\n",
       "        [121., 110., 126.],\n",
       "        [112., 101., 115.],\n",
       "        ...,\n",
       "        [138., 104.,  95.],\n",
       "        [138., 104.,  95.],\n",
       "        [125.,  91.,  82.]],\n",
       "\n",
       "       [[111., 103., 118.],\n",
       "        [121., 110., 126.],\n",
       "        [112., 101., 115.],\n",
       "        ...,\n",
       "        [138., 104.,  95.],\n",
       "        [138., 104.,  95.],\n",
       "        [125.,  91.,  82.]]], dtype=float32)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-269-434953cafb7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Split df into train and test based on label column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdata_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "#Split df into train and test based on label column\n",
    "df_train\n",
    "df_test\n",
    "\n",
    "def data_gen(df, batch_size):\n",
    "\twhile True:\n",
    "\t\tx_batch = numpy.zeros((batch_size, 3, 1024, 1024))\n",
    "\t\ty_batch = numpy.zeros((batch_size, 1))\n",
    "\t\tfor j in range(len(df/batch_size)):\n",
    "\t\t\tb = 0\n",
    "\t\t\tfor m, k in zip(\n",
    "\t\t\t\tdf['filename'].values[j*batch_size:(j+1)*batch_size],\n",
    "\t\t\t\tdf['has_fire'].values[j*batch_size:(j+1)*batch_size]\n",
    "\t\t\t):\n",
    "\t\t\t\timg = Image.open(f'{df[\"Folder\"][b]}/{m}')\n",
    "\t\t\t\timage_red = img.resize((1024, 1024))\n",
    "\t\t\t\tx_batch[b] = img_to_array(image_red)\n",
    "\t\t\t\ty_batch[b] = k\n",
    "\t\t\t\tb += 1\n",
    "\t\t\tyield (x_batch, y_batch)\n",
    "\n",
    "\n",
    "model.fit_generator(\n",
    "\tgenerator=data_gen(\n",
    "\t\tdf_train,\n",
    "\t\tbatch_size=batch_size\n",
    "\t), \n",
    "\tsteps_per_epoch=len(df_train) // batch_size, epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
