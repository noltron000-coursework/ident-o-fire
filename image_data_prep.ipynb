{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”¥ Fire...or No Fire?\n",
    "\n",
    "## **Step 1:** Setup\n",
    "We need to set up the dataframe to initial state.\n",
    "Then we can manipulate it more in later steps, by cleaning it, digesting it, etc.\n",
    "\n",
    "### Import Packages\n",
    "> \"If I have seen further, it is by standing on the shoulders of Giants.\"<br />\n",
    "> &mdash; Isaac Newton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glob crawler for reading files and folders\n",
    "import glob\n",
    "\n",
    "# regex parser for advanced string-parsing\n",
    "import re\n",
    "\n",
    "# pandas used for dataframe manipulation\n",
    "import pandas\n",
    "\n",
    "# numpy is used for odds and ends, like high-efficiency arrays\n",
    "import numpy\n",
    "\n",
    "# python imaging library; used for deconstructing images\n",
    "from PIL import Image\n",
    "\n",
    "# other imports are described as they are used\n",
    "from keras.models import Sequential\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.tensorflow_backend import _get_available_gpus\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl Datafiles\n",
    "The **glob** package is great and sets up our project for success.\n",
    "Be sure you have your directory-structure set up correctly as stated in the README&hellip;\n",
    "Otherwise, I cannot guarentee that this project will work for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all files from dirs in the data dir\n",
    "files = glob.glob('data/*/*.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset in an array\n",
    "dataset = []\n",
    "\n",
    "# loop through every file that \"glob\" found.\n",
    "for filepath in files:\n",
    "\t# regex used for Windows/MacOS compatibility\n",
    "\tfilecrawl = re.split(r'\\\\+|/+', filepath)\n",
    "\n",
    "\t# remove the \"data\" folder entry; its not needed\n",
    "\tfilecrawl = filecrawl[1:]\n",
    "\n",
    "\t# tag images from the fire-images folder as \"fire\"\n",
    "\tif filecrawl[0] == 'Fire images':\n",
    "\t\tfilecrawl.append(1)\n",
    "\telse:\n",
    "\t\tfilecrawl.append(0)\n",
    "\n",
    "\t# add filecrawl findings to dataset\n",
    "\tdataset.append(filecrawl)\n",
    "\t# ==NOTE==\n",
    "\t# Because the \"glob\" package arbitrarily crawls files, the\n",
    "\t# index of an item may not be the same each time this is run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our project's main dataframe\n",
    "dataframe = pandas.DataFrame(dataset, columns=['folder', 'filename', 'fire'])\n",
    "\n",
    "# display shows these tables neatly, shown below\n",
    "display(dataframe.head(), dataframe.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for any duplicate filenames in the dataframe\n",
    "duplicates = dataframe['filename'].duplicated(keep=False)\n",
    "\n",
    "# Select rows with duplicate filenames\n",
    "duplicate_rows = dataframe[duplicates]\n",
    "display(duplicate_rows)\n",
    "\n",
    "# create a warning if duplicates exist\n",
    "if duplicates.sum() != 0:\n",
    "\twarning = Warning(\n",
    "\t\tf'There are {duplicates.sum()}'\n",
    "\t\t' duplicated filenames in the dataframe.'\n",
    "\t\t' proceed with caution.'\n",
    "\t) \n",
    "\tdisplay(warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebalance Datapoints\n",
    "I used [this article][rebalancing] to help figure things out.\n",
    "\n",
    "[rebalancing]: https://towardsdatascience.com/having-an-imbalanced-dataset-here-is-how-you-can-solve-it-1640568947eb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == FIXME ==\n",
    "# this does not seem to be working properly at the moment\n",
    "\n",
    "\"\"\"\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create an object of the classifier, called \"rebalancinator\"\n",
    "rebalancinator = BalancedBaggingClassifier(\n",
    "\tbase_estimator=DecisionTreeClassifier(),\n",
    "\tsampling_strategy='auto',\n",
    "\treplacement=False,\n",
    "\trandom_state=0\n",
    ")\n",
    "\n",
    "'''\n",
    "# train the classifier.\n",
    "rebalancinator.fit(x_train, y_train)\n",
    "preds = rebalancinator.predict(x_train)\n",
    "'''\n",
    "\"\"\"\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "*Why do we need train/test split?*\n",
    "*What does it do?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x: keep the dataframe but drop the fire column\n",
    "x = dataframe.drop(columns=['fire'])\n",
    "\n",
    "# for y: drop everything in the dataframe but fire\n",
    "y = dataframe.loc[:, ['fire']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the built-in \"train test split\" function\n",
    "# to generate the four desireable segments of data.\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "\tx, y, test_size=0.35)\n",
    "\n",
    "x_train = x_train.reset_index().drop('index', 1)\n",
    "y_train = y_train.reset_index().drop('index', 1)\n",
    "x_test = x_test.reset_index().drop('index', 1)\n",
    "y_test = y_test.reset_index().drop('index', 1)\n",
    "\n",
    "display(x_test.head())\n",
    "display(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Image Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_length = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_img_vector(x, index):\n",
    "\t# find filepath\n",
    "\tfilename = x['filename'][index]\n",
    "\tfolder = x['folder'][index]\n",
    "\tfilepath = f'data/{folder}/{filename}'\n",
    "\n",
    "\t# open the image via its filepath\n",
    "\timg = Image.open(filepath)\n",
    "\t# ==NOTE==\n",
    "\t# the Image class was imported from PIL\n",
    "\t# (python image library)\n",
    "\n",
    "\t# remove transparency layer\n",
    "\timg = img.convert('RGB')\n",
    "\n",
    "\t# resize the image\n",
    "\timg = img.resize((image_length, image_length))\n",
    "\n",
    "\t# return the image vector\n",
    "\treturn img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def data_gen(x, y, batch_size):\n",
    "\t# n_batch variables are empty arrays of constant size.\n",
    "\t# x_batch is has RGB values for each pixel's coordinate.\n",
    "\t# y_batch represents whether there is fire or not (0/1).\n",
    "\tx_batch = numpy.zeros((batch_size, image_length, image_length, 3))\n",
    "\ty_batch = numpy.zeros((batch_size, 1))\n",
    "\n",
    "\t# loop through entire dataframe, index by index\n",
    "\tfor index in range(len(x)):\n",
    "\t\t# using batch_size, we can determine \n",
    "\t\tx_batch[index % batch_size] = get_img_vector(x, index)\n",
    "\t\ty_batch[index % batch_size] = y['fire'][index]\n",
    "\n",
    "\t\t# if there has been {batch_size} items, we yield.\n",
    "\t\t# the last batch is an outlier; its batch is smaller.\n",
    "\t\tif ((index + 1) % batch_size == 0\n",
    "\t\tor (index + 1) == len(dataframe)):\n",
    "\t\t\tyield (x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use \"sequential\" mode from keras module\n",
    "# see https://jovianlin.io/keras-models-sequential-vs-functional/\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(16, (4,4), activation='relu', input_shape=(image_length, image_length, 3)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(128, (5, 5), activation='relu', input_shape=(image_length, image_length, 3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "\tloss=binary_crossentropy,\n",
    "\toptimizer=Adadelta(),\n",
    "\tmetrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\tprint(f\"Epoch {epoch+1} / {epochs}\")\n",
    "\tfor x_batch, y_batch in data_gen(x_train, y_train, batch_size):\n",
    "\t\tmodel.train_on_batch(\n",
    "\t\t\tx_batch, y_batch\n",
    "\t\t)\n",
    "\t\tloss, accuracy = model.evaluate(x_batch, y_batch)\n",
    "\t\tprint('accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Affirm Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_value(index):\n",
    "\treturn y_test['fire'][index]\n",
    "\n",
    "def get_y_guess(index):\n",
    "\tfire = model.predict(get_img_vector(x_test, index).reshape(-1, image_length, image_length, 3))\n",
    "\tif fire > 0.0:\n",
    "\t\treturn 1\n",
    "\telse:\n",
    "\t\treturn 0\n",
    "\n",
    "def get_confusion_matrix_objects():\n",
    "\ty_values = []\n",
    "\ty_guesses = []\n",
    "\tfor index in list(range(len(x_test))):\n",
    "\t\ty_values.append(get_y_value(index))\n",
    "\t\ty_guesses.append(get_y_guess(index))\n",
    "\treturn (y_values, y_guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(*get_confusion_matrix_objects()).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "\tf' true positive {tp}\\n'\n",
    "\tf' true negative {tn}\\n'\n",
    "\tf'false positive {fp}\\n'\n",
    "\tf'false negative {fn}\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for index in list(range(50)):\n",
    "\tpredict = model.predict(get_img_vector(x_test, index).reshape(-1, image_length, image_length, 3))\n",
    "\tprint(\n",
    "\t\tf'\\n{predict[0][0]} \\n' \n",
    "\t\t'<img src=\"./data/'\n",
    "\t\tf'{x_train[\"folder\"][index]}'\n",
    "\t\t'/'\n",
    "\t\tf'{x_train[\"filename\"][index]}\">'\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./data/Fire images/images.jpg\">\n",
    "<img src=\"./data/Fire images/11_10_19-mjs_ft_hotel-fire_19183862.jpg\">\n",
    "<img src=\"./data/Fire images/FlamesEverett House Fire.transfer_1461845684828_4041471_ver1.0_640_360.jpg\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
